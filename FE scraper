import requests
from bs4 import BeautifulSoup
import newspaper

def epu_classifier(content):
    str = content.lower()
    E = ["economic" , "economy"]
    U = ["uncertainty" , "uncertain"]
    P = ["regulation", "deficit", "legislation", "reform", "fiscal policy", "monetary policy", "central bank",
         "rbi", "reserve bank", "parliament", "finance ministry", "policy makers", "finance minister", "lawmakers",
         "niti ayog", "economic advisor", "prime minister's office", "pmo", "pmeac", "lok sabha", "tax", "taxes",
         "taxation", "excise duties", "custom duties", "gst"]
    for word in U:
        res_U = str.find(word)
    for word in P:
        res_P = str.find(word)
    for word in E:
        res_E = str.find(word)
    if (res_E >=0 and res_P >=0  and res_U >=0):
        return 1
    else:
        return 0

year = 2013
month = 12
user = "RBI"
while month < 13:
    download_dir1 = "C:/Users/%s/PycharmProjects/read news/FE_scraped_%s_%s.txt" % (user, year, month)
    download_dir2 = "C:/Users/%s/PycharmProjects/read news/FE_scraped_%s_%s.csv" % (user, year, month)
    master_data = {0: {"Title": "Title", "Text": "Text"}}
    txt = open(download_dir1, "w")
    csv = open(download_dir2, "w")

    # for page_no in [1:100]:  create loop for covering all pages
    url = 'https://www.financialexpress.com/archive/%s/%s/?page=%s' % (year, month, page_no)
    print(url)
    page = requests.get(url)
    soup = BeautifulSoup(page.content, 'html.parser')
    body = soup.findAll(class_="stories")
    i = 0
    for articles in body:
        links = articles.findAll("a")
        for link in links:
            link_url = link.get("href")
            art = newspaper.Article(link_url)
            art.download()
            art.parse()
            # print(art.title)
            # print(art.text)
            #master_data[i+1]={"Title":"%s"%art.title, "Text":"%s"%art.text}
            txt.write("Title: %s"%art.title+"\n"+"Text:%s"%art.text)

            csv.write("Title: %s" % art.title + "\t" + "\tEPU:%s\n " % epu_classifier(art.text))
            # print(master_data[i+1])
            i = i+1
    month = month+1
# print(type(article))




